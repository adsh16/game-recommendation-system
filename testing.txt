import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import urllib.parse
import re
import os
import random
from concurrent.futures import ThreadPoolExecutor, as_completed

# Function to load user agents from user_agents.txt
def load_user_agents(file_path):
    with open(file_path, 'r') as file:
        user_agents = [line.strip() for line in file if line.strip()]
    return user_agents

def get_random_user_agent(user_agents):
    """Returns a random user agent string from the list."""
    return random.choice(user_agents)

def get_steam_url(game_name, user_agents):
    """Search for the game on Google and return its Steam URL using a random user agent."""
    headers = {
        'User-Agent': get_random_user_agent(user_agents)
    }
    
    search_query = urllib.parse.quote_plus(f"{game_name} steam store")
    google_search_url = f"https://www.google.com/search?q={search_query}"
    
    try:
        response = requests.get(google_search_url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        for link in soup.find_all('a'):
            href = str(link.get('href'))
            if 'store.steampowered.com/app/' in href:
                try:
                    steam_url = href.split('&')[0].split('=')[1]
                    return steam_url
                except IndexError:
                    match = re.search(r'store\.steampowered\.com/app/\d+', href)
                    if match:
                        return 'https://' + match.group(0)
                    continue
        
        print(f"No Steam store page found for {game_name}")
        return None
        
    except Exception as e:
        print(f"Error searching for {game_name}: {str(e)}")
        return None

def fetch_game_data(game_name, user_agents):
    """Fetch review data and image for a given game from Steam using a random user agent."""
    headers = {
        'User-Agent': get_random_user_agent(user_agents)
    }
    
    steam_url = get_steam_url(game_name, user_agents)
    if not steam_url:
        return game_name, "Not found", 0, 0, None
    
    try:
        response = requests.get(steam_url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        review_count_meta = soup.find('meta', {'itemprop': 'reviewCount'})
        review_count = int(review_count_meta['content']) if review_count_meta else 0
        
        review_desc = soup.find('span', class_='responsive_reviewdesc')
        if review_desc:
            rating_match = re.search(r'(\d+)%', review_desc.text)
            review_rating = int(rating_match.group(1)) if rating_match else 0
        else:
            review_rating = 0
        
        review_summary = soup.find('span', class_='game_review_summary')
        review_summary = review_summary.text.strip() if review_summary else "No reviews"
        
        header_img = soup.find('img', class_='game_header_image_full')
        image_link = header_img['src'] if header_img else None
        
        return game_name, review_summary, review_count, review_rating, image_link
        
    except Exception as e:
        print(f"Error fetching data for {game_name}: {str(e)}")
        return game_name, "Error", 0, 0, None

def save_to_csv(game_data, output_file, file_exists):
    game_name, review_summary, review_count, review_rating, image_link = game_data
    game_data_df = pd.DataFrame({
        'name': [game_name],
        'review_summary': [review_summary],
        'review_count': [review_count],
        'review_rating': [review_rating],
        'image_link': [image_link]
    })
    game_data_df.to_csv(output_file, mode='a', header=not file_exists, index=False)

def main():
    try:
        # Load user agents from file
        user_agents = load_user_agents('user_agents.txt')
        
        # Read the CSV with game names
        df = pd.read_csv('games.csv')
        output_file = 'games_with_reviews.csv'
        file_exists = os.path.isfile(output_file)
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(fetch_game_data, game_name, user_agents): game_name for game_name in df['name']}
            
            for future in as_completed(futures):
                game_name = futures[future]
                try:
                    game_data = future.result()
                    save_to_csv(game_data, output_file, file_exists)
                    file_exists = True
                    print(f"Finished processing {game_name}")
                except Exception as e:
                    print(f"Error processing {game_name}: {str(e)}")
                
                # Add a random delay between 1-3 seconds after each request to avoid rate-limiting
                time.sleep(random.uniform(1, 3))
        
        print("Processing complete! Data saved to games_with_reviews.csv")
        
    except Exception as e:
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    main()
